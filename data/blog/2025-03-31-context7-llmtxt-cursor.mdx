---
title: "Introducing Context7: Instant Context for LLMs and Developers"
slug: context7-llmtxt-cursor
authors:
  - enes
tags: [vector, context7, ai]
---

I am excited to introduce our new project, Context7. I have been using coding assistants around a year. With Context7, my objective is to solve a problem I witness:
LLMs either halucinate or mix different versions of software libraries unless the library API is very stable for a long time.  

## TLDR
- Context7 is a web service provides up-to-date high quality context for software packages.
- Context data is composed of code snippets used in documentation of the package.
- Context is generated by parsing open source documentation repositories of projects.
- It is much more than just copying the documentation. Context is composed of code snippets and their descriptions generated by LLMs.
- User can access context of indexed packages in milliseconds.
- User can add new packages to the index in seconds up to minutes depending on size of the package.

## Why?

We want to fix two problems:
1- AI Knowledge Cutoff
2- Version Mess

### AI Knowledge Cutoff
You start a project using Cursor. You want to use upstash-workflow library which has been release on December 2024, but your model's knowledge cutoff is November 2024. Then your agent starts to halucinate. To deal this, developers copies and pastes the documentation of the library. There are multiple issues with this approach:
- Most of the documentation pages include lots of data which are not useful for LLMs. LLMs just need to know API and code examples. They can generate the REST.
- LLMs has max context size so you can not copy the whole documentation. 
- Last but not least it is very inconvenient to go to documentation sites and manually copy the sections.
                                                                                                                                                           
Context7 gives you:
- Freshly parsed context
- Just code snippets with description, no redundant information.
- You can control the token size.
- You can rerank the context on special topics for a focused and refined result.


### Version Mess
You want to create a Next.js website. The LLM start to use the version 15. But at some point you realize there code and config parts from different versions. Now it is hard to fix things. Context7 gives you the code snippets from the latest version. They are updated periodically. So when you send the context, you ensure coding assistant will use the latest version.

## Why is Context7 free?

We are engineers of Upstash. Upstash have a large infrastructure serving over 1000 paying customers. We have hundreds of servers in 3 cloud providers. We want to run Context7 on our infrastructure using redundant resources. We want to help developers to adapt AI to their projects. We aim to keep Context7 free for personal and educational use. 

## How is Context7 different from other LLM context providers?

Context7 is not just a crawler which parses the docs. Context7 uses an algorithm to extract the most relevant data with minimum token cost. Here how we do it:

1- Parsing: We parse the docs and extract the code snippets.
2- Enrichment: We use LLM toenrich each code snippet with description also adding context of the page where the code snippet is located.
3- Vectorization: We vectorize the code snippets and descriptions for efficient search.
4- Reranking: We rerank the code snippets and descriptions using LLM. The objective is to provide the most relevant code snippets and descriptions to create a developer guide.
5- Caching: We cache the code snippets and guides for best performance. Sure, we use Redis üí™üèª.

Most importantly, we use Context7 on our own projects. So we continuously improve it the above algorithms. Please help us by sharing your feedback.

## Use Cases

- Developers can use Context7 on coding assistants (Cursor, Windsurf, Github Copilot, etc.) by pasting the LLM context from Context7. Example:

```txt
Build a Next.js website with Tailwind CSS. Use the attached context for the Next.js api.

%COPY PASTE LLM CONTEXT FROM CONTEXT7%

```

- Developers can use MCP server of Context7 to provide context in automated way to coding assistants.

- Agent implementations can programmatically consume Context7 API to get the most up-to-date context for a given package.


## What is llms.txt?
llms.txt is a new way to interact with LLMs. It is like robots.txt for LLMs. Different than robots.txt, llms.txt aims to optimize the content for LLMs rather than crawlers. While robots.txt aims to give the full content of the website, llms.txt aims to give the most relevant and summarized content.

### Does Context7 generate llms.txt?

Yes, but in a more special format. Context7 specializes open source software packages. Its output includes code snippets which are to be used by coding assistants like Cursor, Windsurf, etc.

### I am an author of an open source project. How can I benefit from Context7?

You can add your project to the Context7 index using [the web interface](https://context7.com/add-package). If you need to add more details (e.g. exluded folders, etc.) you can send a PR to the [Context7 GitHub repository](https://github.com/upstash/context7/tree/master/packages).

Once your project is indexed, you can share the your raw context with others using the link. Example:
[https://context7.com/nextjs/llm.txt](https://context7.com/nextjs/llm.txt)

## What is a coding assistant? What is a coding agent? 

- Coding assistants are tools that help developers to write code. Coding agents are tools that writes code.

- Coding assistants are used by developers. Agents can be used by non technical people.

- Developers are in control while using coding assistants. Coding agents can build the project end to end without human intervention.

- Coding assistants examples: Cursor, Windsurf, Github Copilot, etc.

- Coding agents examples: V0, Replit, Lovable, etc.

- Cursor and Windsurf support also agent mode which makes them more like a hybrid between assistant and agent.

- My opinion: If you are a beginner developeror non-technical then try coding agents. If you are medium to advanced developer then use coding assistants.


## What is Cursor? Why is it special?
Cursor and Windsurf are IDEs built on top of VSCode. They are special because they are built to work integrated with AI. Using Cursor and Windsurf, you can get help from LLMs any time while coding. They are pro actively suggest code completions which positively surprise many developers. Both have a limited free tier which is enough to try the tool. For continued use, you can subscribe to paid plans.


## Using Context7 with Cursor and Windsurf
- You can use Context7 with any coding assistant or agent. Context7 provides code examples to these tools to make them more accurate.

- You can use Context7 in 2 ways:
1- Manually copy paste the context to the prompt.
2- Use MCP server of Context7 to provide context in automated way to coding assistants.


## Getting Started with Context7

1- Getting context for a package:
Go to [context7.com](https://context7.com) and search for a package. You will see the context for the package.

You can set the context size and rerank the context on special topics for a focused and refined result.

There is a copy button to copy the context to your clipboard. Now include the context in your prompt.


2- Getting context using MCP server. Install the MCP server to your machine.
```bash
to be updated
```

Now add your MCP server to your coding assistant by:
```bash
to be updated
```

3- Adding a package to the index. If you can not find the package you are looking for, you can add it to the index.

Simply use the form on the [add package page](https://context7.com/add-package).

If the package requires additional configuration, you can send a PR to the [Context7 GitHub repository](https://github.com/upstash/context7/tree/master/packages).


## Roadmap
- Public MCP server. (Currently MCP server is in private preview.)

- Public API and SDKs for Context7.

- Support for older version.

- Support for private packages.

- Search over the code snippets.

- Multi project/package context.

- Filtering by programming language.





















 









